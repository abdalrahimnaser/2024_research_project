{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9695\n",
      "Epoch [2/10], Loss: 0.8194\n",
      "Epoch [3/10], Loss: 0.5266\n",
      "Epoch [4/10], Loss: 0.8191\n",
      "Epoch [5/10], Loss: 1.3408\n",
      "Epoch [6/10], Loss: 1.3926\n",
      "Epoch [7/10], Loss: 0.7142\n",
      "Epoch [8/10], Loss: 0.7524\n",
      "Epoch [9/10], Loss: 0.8996\n",
      "Epoch [10/10], Loss: 0.5814\n",
      "Training completed!\n",
      "Model has been exported to simple_dnn.onnx\n",
      "The ONNX model is successfully exported and verified!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abood\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\brevitas\\quant_tensor\\__init__.py:68: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  training = torch.tensor(training, dtype=torch.bool)\n",
      "c:\\Users\\abood\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\brevitas\\quant_tensor\\__init__.py:66: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  signed = torch.tensor(signed, dtype=torch.bool)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from brevitas.nn import QuantLinear, QuantReLU\n",
    "from brevitas.quant import Int8WeightPerTensorFloat, Int8ActPerTensorFloat\n",
    "import onnx\n",
    "\n",
    "class QuantizedDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedDNN, self).__init__()\n",
    "        self.fc1 = QuantLinear(10, 50, weight_bit_width=8, weight_quant=Int8WeightPerTensorFloat, bias=True)\n",
    "        self.relu1 = QuantReLU(bit_width=8, act_quant=Int8ActPerTensorFloat)\n",
    "        self.fc2 = QuantLinear(50, 20, weight_bit_width=8, weight_quant=Int8WeightPerTensorFloat, bias=True)\n",
    "        self.relu2 = QuantReLU(bit_width=8, act_quant=Int8ActPerTensorFloat)\n",
    "        self.fc3 = QuantLinear(20, 1, weight_bit_width=8, weight_quant=Int8WeightPerTensorFloat, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = QuantizedDNN()\n",
    "\n",
    "# Generate random dataset\n",
    "X = torch.randn(100, 10)  # 100 samples, 10 features each\n",
    "y = torch.randn(100, 1)   # 100 target values\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Create a dummy input tensor with the appropriate input size (batch size, input features)\n",
    "dummy_input = torch.randn(1, 10)\n",
    "\n",
    "# Define the path where the ONNX model will be saved\n",
    "onnx_path = \"simple_dnn.onnx\"\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    model,                      # Model to be exported\n",
    "    dummy_input,                # Dummy input tensor\n",
    "    onnx_path,                  # Output ONNX file path\n",
    "    input_names=[\"input\"],      # Name of the input layer\n",
    "    output_names=[\"output\"],    # Name of the output layer\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}  # Support dynamic batch size\n",
    ")\n",
    "\n",
    "print(f\"Model has been exported to {onnx_path}\")\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "\n",
    "# Check that the model is well-formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "print(\"The ONNX model is successfully exported and verified!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
